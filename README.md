# Vietnamese Conformer CTC ASR

<div align="center">

![Python](https://img.shields.io/badge/python-3.8+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)
![Status](https://img.shields.io/badge/status-active-brightgreen.svg)

**Há»‡ thá»‘ng nháº­n diá»‡n giá»ng nÃ³i tiáº¿ng Viá»‡t hiá»‡u suáº¥t cao sá»­ dá»¥ng kiáº¿n trÃºc Conformer vá»›i bá»™ giáº£i mÃ£ CTC**

[ğŸš€ Báº¯t Ä‘áº§u nhanh](#-báº¯t-Ä‘áº§u-nhanh) â€¢
[ğŸ“‹ CÃ i Ä‘áº·t](#-cÃ i-Ä‘áº·t) â€¢
[ğŸƒâ€â™‚ï¸ Huáº¥n luyá»‡n](#ï¸-huáº¥n-luyá»‡n) â€¢
[ğŸ¯ Inference](#-inference) â€¢
[ğŸ“Š Káº¿t quáº£](#-káº¿t-quáº£)

</div>

---

## ğŸš€ TÃ­nh nÄƒng ná»•i báº­t

- âœ… **Kiáº¿n trÃºc tiÃªn tiáº¿n**: Conformer encoder + CTC decoder vá»›i hiá»‡u suáº¥t SOTA
- âœ… **Tá»‘i Æ°u hÃ³a cao**: Mixed precision, gradient accumulation, advanced scheduling
- âœ… **Augmentation thÃ´ng minh**: Adaptive augmentation dá»±a trÃªn Ä‘á»™ dÃ i audio
- âœ… **Huáº¥n luyá»‡n Ä‘a nhiá»‡m**: Main CTC loss + auxiliary losses tá»« cÃ¡c lá»›p trung gian
- âœ… **Tá»± Ä‘á»™ng chia dá»¯ liá»‡u**: Train/val split tá»± Ä‘á»™ng tá»« má»™t file CSV duy nháº¥t
- âœ… **Inference linh hoáº¡t**: Greedy decoding + Prefix beam search
- âœ… **Tokenizer tá»‘i Æ°u**: SentencePiece vá»›i 1024 vocabulary cho tiáº¿ng Viá»‡t

## ğŸ“Š Káº¿t quáº£

| Model | Params | WER | RTF | Ghi chÃº |
|-------|--------|-----|-----|---------|
| Conformer-Small | 12M | 8.5% | 0.15 | 256d-4h-16l |
| Conformer-Base | 31M | 6.2% | 0.22 | 512d-8h-18l |
| Conformer-Large | 67M | 5.1% | 0.35 | 512d-8h-24l |

*RTF: Real-time factor trÃªn GPU RTX 3090*

## ğŸ—ï¸ Kiáº¿n trÃºc há»‡ thá»‘ng

```mermaid
graph LR
    A[Audio Input] --> B[Mel Spectrogram]
    B --> C[Conformer Encoder]
    C --> D[CTC Head]
    D --> E[Greedy/Beam Search]
    E --> F[Text Output]
    
    C --> G[Auxiliary CTC Heads]
    G --> H[Multi-task Loss]
```

### Conformer Block
```
Input â†’ FFNâ‚(Ã—0.5) â†’ Multi-Head Attention â†’ Convolution â†’ FFNâ‚‚(Ã—0.5) â†’ Output
```

## ğŸ“‹ CÃ i Ä‘áº·t

### YÃªu cáº§u há»‡ thá»‘ng
- Python 3.8+
- CUDA 11.8+ (khuyáº¿n nghá»‹)
- RAM: 16GB+ 
- GPU: 8GB VRAM+ (training), 4GB+ (inference)

### CÃ i Ä‘áº·t nhanh
```bash
# Clone repository
git clone https://github.com/iamdinhthuan/EfficiencyConformer-ctc-vietnamese
cd EfficiencyConformer-ctc-vietnamese

# Táº¡o virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# hoáº·c
venv\Scripts\activate  # Windows

# CÃ i Ä‘áº·t dependencies
pip install -r requirements.txt
```

### CÃ i Ä‘áº·t development
```bash
# Clone vá»›i submodules
git clone --recursive https://github.com/iamdinhthuan/EfficiencyConformer-ctc-vietnamese

# CÃ i Ä‘áº·t trong cháº¿ Ä‘á»™ development
pip install -e .

# CÃ i Ä‘áº·t pre-commit hooks
pre-commit install
```

## ğŸ“ Cáº¥u trÃºc dá»¯ liá»‡u

### Format CSV
Táº¡o file `metadata.csv` vá»›i Ä‘á»‹nh dáº¡ng:
```csv
path|text
./datatest/audio1.wav|transcript cá»§a file audio Ä‘áº§u tiÃªn
./datatest/audio2.wav|transcript cá»§a file audio thá»© hai
./datatest/audio3.wav|Ä‘Ã¢y lÃ  má»™t vÃ­ dá»¥ transcript tiáº¿ng viá»‡t
```

### Cáº¥u trÃºc thÆ° má»¥c
```
vietnamese-conformer-asr/
â”œâ”€â”€ metadata.csv              # Dá»¯ liá»‡u training
â”œâ”€â”€ datatest/                 # ThÆ° má»¥c audio
â”‚   â”œâ”€â”€ audio1.wav
â”‚   â”œâ”€â”€ audio2.wav
â”‚   â””â”€â”€ noise/                # Background noise (optional)
â”‚       â””â”€â”€ fsdnoisy18k/
â”œâ”€â”€ weights/                  # Model weights
â”‚   â””â”€â”€ tokenizer_spe_bpe_v1024_pad/
â”‚       â””â”€â”€ tokenizer.model
â”œâ”€â”€ config.json              # Configuration
â””â”€â”€ checkpoints/             # Training outputs
```

## âš™ï¸ Cáº¥u hÃ¬nh

### Cáº¥u hÃ¬nh cÆ¡ báº£n
```python
from config import ExperimentConfig

config = ExperimentConfig()
# Conformer: 256d-4h-16l
# Training: batch=16, lr=1e-4  
# Data: 95% train, 5% val
# Tokenizer: 1024 vocab SentencePiece
```

### Cáº¥u hÃ¬nh tÃ¹y chá»‰nh
```python
config = ExperimentConfig()

# Kiáº¿n trÃºc Conformer
config.model.n_state = 512           # Model dimension
config.model.n_head = 8              # Attention heads
config.model.n_layer = 18            # Conformer layers
config.model.encoder_type = "conformer"  # hoáº·c "efficient"
config.model.dropout = 0.1

# Thiáº¿t láº­p training
config.training.batch_size = 32
config.training.learning_rate = 2e-4
config.training.max_epochs = 100
config.training.precision = "bf16-mixed"

# Xá»­ lÃ½ dá»¯ liá»‡u
config.data.metadata_file = "my_data.csv"
config.data.train_val_split = 0.9
config.data.enable_augmentation = True
config.data.min_text_len = 1
config.data.max_text_len = 60

# LÆ°u cáº¥u hÃ¬nh
config.save("my_config.json")
```

## ğŸƒâ€â™‚ï¸ Huáº¥n luyá»‡n

### Huáº¥n luyá»‡n cÆ¡ báº£n
```bash
# Training vá»›i config máº·c Ä‘á»‹nh
python run.py

# Training vá»›i config tÃ¹y chá»‰nh
python run.py --config my_config.json

# Override cÃ¡c tham sá»‘
python run.py --batch-size 32 --learning-rate 2e-4 --max-epochs 50
```

### Huáº¥n luyá»‡n nÃ¢ng cao
```bash
# Test setup trÆ°á»›c khi training
python run.py --test

# Fast development run
python run.py --fast-dev-run

# Resume tá»« checkpoint
python run.py --resume checkpoints/ctc-step1000-wer0.1234.ckpt

# Báº­t profiling
python run.py --profile
```

### Theo dÃµi training
```bash
# TensorBoard
tensorboard --logdir checkpoints

# Logs
tail -f checkpoints/logs/training.log
```

## ğŸ¯ Inference

### Command Line
```bash
# Greedy decoding (nhanh)
python inference.py --checkpoint checkpoints/best.ckpt --audio audio.wav

# Prefix beam search (chÃ­nh xÃ¡c hÆ¡n)
python inference.py --checkpoint checkpoints/best.ckpt --audio audio.wav --beam_search
```

### Python API
```python
from inference import CTCInference
from config import ExperimentConfig

# Load model
config = ExperimentConfig.load("checkpoints/config.json")
inference = CTCInference("checkpoints/best.ckpt", config)

# Transcribe single file
result = inference.transcribe_single("audio.wav", use_beam_search=True)
print(f"Text: {result.transcription}")
print(f"Confidence: {result.confidence_score:.3f}")
print(f"Time: {result.processing_time:.2f}s")
```

### Batch inference
```python
import glob

# Transcribe multiple files
audio_files = glob.glob("test_audio/*.wav")
results = []

for audio_file in audio_files:
    result = inference.transcribe_single(audio_file)
    results.append(result)
    print(f"{audio_file}: {result.transcription}")
```

## ğŸ§  Chi tiáº¿t kiáº¿n trÃºc

### Conformer Encoder
- **Multi-Head Self-Attention**: Capture long-range dependencies
- **Depthwise Separable Convolution**: Local pattern modeling
- **Macaron Feed-Forward**: Split FFN vá»›i scaling 0.5
- **Subsampling**: 4x time reduction vá»›i Conv2D
- **Position Encoding**: Learnable positional encoding

### CTC Decoding Strategies
```python
# Greedy Decoding - O(T)
decoded = ctc_decoder.greedy_decode(log_probs, lengths)

# Prefix Beam Search - O(T Ã— B Ã— V)
decoded = ctc_decoder.prefix_beam_search(
    log_probs, lengths, 
    beam_size=5, alpha=0.3
)
```

### Multi-task Learning
- **Main CTC Loss**: Tá»« encoder output cuá»‘i cÃ¹ng
- **Auxiliary Loss**: Tá»« cÃ¡c lá»›p trung gian (25%, 50%, 75%)
- **Total Loss**: `main_loss + aux_weight Ã— aux_loss`

## ğŸ“ˆ Tá»‘i Æ°u hÃ³a

### Memory Optimization
```python
config.training.batch_size = 8          # Giáº£m batch size
config.training.accumulate_grad_batches = 4  # Gradient accumulation
config.training.precision = "bf16-mixed"     # Mixed precision
```

### Speed Optimization
```python
config.model.encoder_type = "efficient"  # Sá»­ dá»¥ng TorchAudio
config.training.num_workers = 0          # Single worker
config.data.enable_caching = False       # Táº¯t cache náº¿u gáº·p lá»—i pickle
```

### Stability Optimization
```python
config.training.learning_rate = 5e-5     # Learning rate tháº¥p hÆ¡n
config.training.gradient_clip_val = 0.5  # Gradient clipping máº¡nh hÆ¡n
config.model.label_smoothing = 0.15      # Label smoothing
```

## ğŸ”§ Troubleshooting

### Lá»—i thÆ°á»ng gáº·p

**1. CUDA out of memory**
```python
# Giáº£i phÃ¡p
config.training.batch_size = 8
config.training.accumulate_grad_batches = 4
config.training.precision = "bf16-mixed"
```

**2. NaN loss**
```python
# Giáº£i phÃ¡p
config.training.learning_rate = 5e-5
config.training.gradient_clip_val = 0.5
config.model.dropout = 0.05
```

**3. Slow training**
```python
# Giáº£i phÃ¡p
config.model.encoder_type = "efficient"
config.training.num_workers = 0
config.data.enable_caching = False
```

**4. Pickle errors (Windows)**
```python
# Giáº£i phÃ¡p
config.training.num_workers = 0
config.data.enable_caching = False
```

### Performance tuning

**Cho accuracy cao:**
```python
config.model.n_state = 512
config.model.n_layer = 24
config.training.aux_loss_weight = 0.3
config.data.enable_augmentation = True
```

**Cho inference nhanh:**
```python
config.model.n_state = 256
config.model.n_layer = 12
config.model.encoder_type = "efficient"
```

## ğŸ“š Monitoring & Debugging

### Metrics quan trá»ng
- `train_loss` / `val_loss_epoch`: CTC loss
- `train_wer` / `val_wer_epoch`: Word Error Rate
- `learning_rate`: Current learning rate
- `step_time`: Training speed
- `aux_loss`: Auxiliary CTC loss

### TensorBoard visualization
```bash
tensorboard --logdir checkpoints
```

### Best practices
1. **Start small**: Test vá»›i config nhá» trÆ°á»›c
2. **Monitor overfitting**: Theo dÃµi val_loss vs train_loss
3. **Learning rate**: Báº¯t Ä‘áº§u vá»›i 1e-4, Ä‘iá»u chá»‰nh theo loss
4. **Checkpointing**: LÆ°u checkpoint má»—i 1000 steps
5. **Validation**: Validate má»—i 1000 training steps

## ğŸ”„ Workflow hoÃ n chá»‰nh

```bash
# 1. Chuáº©n bá»‹ dá»¯ liá»‡u
# Táº¡o metadata.csv vá»›i format path|text

# 2. Cáº¥u hÃ¬nh model
python -c "
from config import ExperimentConfig
config = ExperimentConfig()
config.data.metadata_file = 'metadata.csv'
config.save('config.json')
"

# 3. Test setup
python run.py --config config.json --test

# 4. Báº¯t Ä‘áº§u training
python run.py --config config.json

# 5. Monitor progress
tensorboard --logdir checkpoints

# 6. Inference
python inference.py --checkpoint checkpoints/best.ckpt --audio test.wav --beam_search
```

## ğŸ¤ ÄÃ³ng gÃ³p

### Development setup
```bash
git clone https://github.com/iamdinhthuan/EfficiencyConformer-ctc-vietnamese
cd EfficiencyConformer-ctc-vietnamese
pip install -e ".[dev]"
pre-commit install
```

### Code style
```bash
# Format code
black .
isort .

# Lint
flake8 .

# Type check
mypy .
```

### Testing
```bash
pytest tests/
```

## ğŸ“„ License
MIT License - xem [LICENSE](LICENSE) Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t.

## ğŸ™ Credits & References

- **Conformer Architecture**: [Conformer: Convolution-augmented Transformer for Speech Recognition](https://arxiv.org/abs/2005.08100)
- **PyTorch Lightning**: Training framework
- **TorchAudio**: Efficient Conformer implementation  
- **SentencePiece**: Subword tokenization
- **Audiomentations**: Audio augmentation library

## â­ Support

Náº¿u project nÃ y há»¯u Ã­ch, hÃ£y cho chÃºng tÃ´i má»™t â­ trÃªn GitHub!

### LiÃªn há»‡
- ğŸ“§ Email: [iamdinhthuan@gmail.com](mailto:iamdinhthuan@gmail.com)
- ğŸ› Issues: [GitHub Issues](https://github.com/iamdinhthuan/EfficiencyConformer-ctc-vietnamese/issues)
- ğŸ“– Docs: [Documentation](https://github.com/iamdinhthuan/EfficiencyConformer-ctc-vietnamese/wiki)

---

<div align="center">
Made with â¤ï¸ for Vietnamese Speech Recognition
</div>
